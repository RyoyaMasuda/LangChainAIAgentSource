{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa9f44d",
   "metadata": {},
   "source": [
    "# AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ§‹ç¯‰\n",
    "\n",
    "## 1.æº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b8731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Annotated, Literal, TypedDict\n",
    "import uuid\n",
    "\n",
    "# LangChain / OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "\n",
    "# LangGraph Core\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿\n",
    "load_dotenv()\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«å\n",
    "MODEL_NAME = \"gpt-5-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b14fa3",
   "metadata": {},
   "source": [
    "## 2.ãƒ„ãƒ¼ãƒ«ã®å®šç¾©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c1686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ„ãƒ¼ãƒ«ã®åˆæœŸåŒ–\n",
    "tavily_search = TavilySearch(\n",
    "    max_results=2,                 # å–å¾—ã™ã‚‹æ¤œç´¢çµæœã®æ•°\n",
    "    search_depth=\"basic\",          # \"basic\" (é«˜é€Ÿ) ã‹ \"advanced\" (é«˜å“è³ª)\n",
    "    include_answer=False,          # TavilyãŒç”Ÿæˆã—ãŸçŸ­ã„å›ç­”ã‚’å«ã‚ãªã„\n",
    "    include_raw_content=False,     # HTMLã®ç”Ÿã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å«ã‚ã‚‹ã‹ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»å¢—ã«æ³¨æ„ï¼‰\n",
    "    include_images=False,          # ç”»åƒURLã‚’å«ã‚ã‚‹ã‹\n",
    "    # include_domains=[\"go.jp\"],   # ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ã¿æ¤œç´¢ã™ã‚‹å ´åˆ\n",
    "    # exclude_domains=[\"wikipedia.org\"] # ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’é™¤å¤–ã™ã‚‹å ´åˆ\n",
    ")\n",
    "\n",
    "# Tavilyã®æ¤œç´¢çµæœã ã‘ã‚’ã€LLMãŒèª­ã¿ã‚„ã™ã„å½¢ã«æ•´å½¢ã™ã‚‹é–¢æ•°\n",
    "def format_tavily_results(tavily_response: dict) -> str:\n",
    "    results = tavily_response.get(\"results\", [])\n",
    "    if not results:\n",
    "        return \"ï¼ˆæ¤œç´¢çµæœãªã—ï¼‰\"\n",
    "\n",
    "    lines = []\n",
    "    for i, r in enumerate(results, 1):\n",
    "        title = r.get(\"title\", \"\")\n",
    "        content = r.get(\"content\", \"\")\n",
    "        url = r.get(\"url\", \"\")\n",
    "        lines.append(f\"[{i}] {title}\\n{content}\\nsource: {url}\")\n",
    "    return \"\\n\\n\".join(lines)\n",
    "\n",
    "# TavilySearchã®ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹(dict/JSON)ã‚’æ•´å½¢ã—ã¦è¿”ã™ãƒ©ãƒƒãƒ‘ãƒ¼Tool\n",
    "@tool\n",
    "def tavily_search_formatted(query: str) -> str:\n",
    "    \"\"\"Webæ¤œç´¢ï¼ˆTavilyï¼‰ã€‚ä¸Šä½çµæœã‚’æ•´å½¢ã—ã¦è¿”ã™ã€‚\"\"\"\n",
    "    tavily_response = tavily_search.invoke({\"query\": query})\n",
    "    return format_tavily_results(tavily_response)\n",
    "\n",
    "tools = [tavily_search_formatted]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfee14c",
   "metadata": {},
   "source": [
    "## 3.ã‚¹ãƒ†ãƒ¼ãƒˆã€ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e5f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # add_messagesã‚’ä½¿ã†ã“ã¨ã§å±¥æ­´ã‚’è¿½è¨˜å‹ã§ç®¡ç†\n",
    "    research_messages: Annotated[list[BaseMessage], add_messages]\n",
    "    analysis_messages: Annotated[list[BaseMessage], add_messages]\n",
    "    # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãªã©ã¯ä¸Šæ›¸ãã§OK\n",
    "    loop_count: int\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–\n",
    "model = ChatOpenAI(model=MODEL_NAME)\n",
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d177bdac",
   "metadata": {},
   "source": [
    "## 4.ãƒãƒ¼ãƒ‰ã®å®šç¾©\n",
    "\n",
    "### ãƒ‡ãƒãƒƒã‚°ç”¨é–¢æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3862f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒãƒƒã‚°ç”¨é–¢æ•°\n",
    "DEBUG_MODE = True  # ã“ã“ã‚’Trueã«ã™ã‚‹ã¨è©³ç´°ãƒ­ã‚°ãŒå‡ºã¾ã™\n",
    "\n",
    "def print_debug(title, content):\n",
    "    if DEBUG_MODE:\n",
    "        print(f\"\\nğŸ› [DEBUG] {title}:\\n{content}\\n\" + \"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4de5700",
   "metadata": {},
   "source": [
    "### ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ab58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOOL_LOOPS = 3\n",
    "\n",
    "research_prompt_text = \"\"\"\n",
    "ã‚ãªãŸã¯äº‹æ¥­ãƒªã‚µãƒ¼ãƒæ‹…å½“ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ†ãƒ¼ãƒã«ã¤ã„ã¦ã€å¸‚å ´è¦æ¨¡ã€ä¸»è¦ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã€æŠ€è¡“èª²é¡Œãªã©ã‚’Webæ¤œç´¢ã§èª¿æŸ»ã—ã¦ãã ã•ã„ã€‚å¿…è¦ã«å¿œã˜ã¦æœ€é©ãªãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚\n",
    "ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’è¡Œã£ãŸå¾Œã«å›ç­”ã™ã‚‹å ´åˆï¼ˆãƒ„ãƒ¼ãƒ«çµæœã«URLãŒå«ã¾ã‚Œã‚‹å ´åˆã®ã¿ï¼‰ã¯ä»¥ä¸‹ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚\n",
    "ãƒ»å›ç­”ã®æœ«å°¾ã«å‚ç…§ã—ãŸsourceç•ªå·ï¼ˆä¾‹ï¼š[1][2]ï¼‰ã‚’ä»˜ã‘ã‚‹\n",
    "ãƒ»æœ€å¾Œã«sourceç•ªå·ã¨urlã‚’ç®‡æ¡æ›¸ãã§åˆ—æŒ™ã™ã‚‹\n",
    "\"\"\"\n",
    "\n",
    "research_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", research_prompt_text),\n",
    "    MessagesPlaceholder(variable_name=\"research_messages\")\n",
    "])\n",
    "research_chain = research_prompt | model_with_tools\n",
    "\n",
    "def research_agent(state: State) -> Command[Literal[\"tools\", \"summary_agent\"]]:\n",
    "    print(\"ğŸ” ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: æ€è€ƒä¸­...\")\n",
    "\n",
    "    response = research_chain.invoke({\"research_messages\": state[\"research_messages\"]})\n",
    "\n",
    "    update = {\"research_messages\": [response]}\n",
    "    current_count = state.get(\"loop_count\", 0)\n",
    "\n",
    "    # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—åˆ¤å®š\n",
    "    if response.tool_calls:\n",
    "        # ãƒ‡ãƒãƒƒã‚°ï¼šè¤‡æ•° tool_call ã«å¯¾å¿œã—ã¦è¡¨ç¤º\n",
    "        tool_names = [tc.get(\"name\") for tc in response.tool_calls]\n",
    "        print(f\"ğŸ‘‰ ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—: {tool_names}\")\n",
    "        if DEBUG_MODE:\n",
    "            for i, tc in enumerate(response.tool_calls, 1):\n",
    "                print_debug(f\"Tool Call #{i} ({tc.get('name')})\", tc.get(\"args\"))\n",
    "\n",
    "        if current_count < MAX_TOOL_LOOPS:\n",
    "            return Command(update=update, goto=\"tools\")\n",
    "        else:\n",
    "            # ä¸Šé™åˆ°é”ã§ã‚‚ã€ç›´å‰ã®AIMessageã¯å¿…ãšå±¥æ­´ã«æ®‹ã™\n",
    "            print(\"âš ï¸ ãƒ«ãƒ¼ãƒ—ä¸Šé™ã®ãŸã‚ã€ã‚µãƒãƒªãƒ¼ã¸å¼·åˆ¶ç§»è¡Œã—ã¾ã™ã€‚\")\n",
    "            return Command(update=update, goto=\"summary_agent\")\n",
    "\n",
    "    print(\"âœ… ãƒªã‚µãƒ¼ãƒå®Œäº†ã€‚ã‚µãƒãƒªãƒ¼ã¸ç§»è¡Œã—ã¾ã™ã€‚\")\n",
    "    return Command(update=update, goto=\"summary_agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6350edc8",
   "metadata": {},
   "source": [
    "### ãƒ„ãƒ¼ãƒ«ãƒãƒ¼ãƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ec666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToolNodeã®ä½¿ç”¨ï¼ˆä¸¦åˆ—ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚‚è‡ªå‹•å¯¾å¿œï¼‰\n",
    "tool_node = ToolNode(tools, messages_key=\"research_messages\")\n",
    "\n",
    "# ãƒ„ãƒ¼ãƒ«ãƒãƒ¼ãƒ‰ï¼ˆãƒ©ãƒƒãƒ‘ãƒ¼ï¼‰\n",
    "def research_tool_node(state: State) -> Command[Literal[\"research_agent\"]]:\n",
    "    print(\"ğŸ› ï¸ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œä¸­...\")\n",
    "\n",
    "    # æ¨™æº–ã®ToolNodeã‚’å®Ÿè¡Œ\n",
    "    result = tool_node.invoke({\"research_messages\": state[\"research_messages\"]})\n",
    "    \n",
    "    # ãƒ‡ãƒãƒƒã‚°: ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œçµæœã‚’è¡¨ç¤º\n",
    "    # ToolMessageã®contentã‚’è¡¨ç¤º\n",
    "    last_message = result[\"research_messages\"][-1]\n",
    "    tool_text = last_message.content\n",
    "    tool_text = tool_text if isinstance(tool_text, str) else str(tool_text)\n",
    "    print_debug(\"Tool Output\", tool_text[:300] + \"... (çœç•¥)\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"research_messages\": result[\"research_messages\"],\n",
    "            \"loop_count\": state.get(\"loop_count\", 0) + 1\n",
    "        },\n",
    "        goto=\"research_agent\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0d3aca",
   "metadata": {},
   "source": [
    "### ã‚µãƒãƒªãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚µãƒãƒªãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ã‚ãªãŸã¯å„ªç§€ãªæ›¸è¨˜ã§ã™ã€‚ä»¥ä¸‹ã®ã€Œèª¿æŸ»ãƒ­ã‚°ã€ã®å†…å®¹ã‚’è¦ç´„ã—ã€æ¬¡ã®å¸‚å ´åˆ†æãƒãƒ¼ãƒ ãŒä½¿ãˆã‚‹è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚èª¿æŸ»ãƒ­ã‚°ã«å«ã¾ã‚Œã‚‹ source: URL ã‚’å‚ç…§ã—ã€æ–­å®šçš„ãªäº‹å®Ÿã«ã¯å¯èƒ½ãªé™ã‚Š [n] ã‚’ä»˜ã‘ã€æœ«å°¾ã«å‚ç…§ä¸€è¦§ã‚’ä»˜ã‘ã‚‹ã€‚å­˜åœ¨ã—ãªã„å‡ºå…¸ã¯ä½œã‚‰ãªã„ã€‚\"),\n",
    "    (\"human\", \"ä»¥ä¸‹ãŒèª¿æŸ»ãƒ­ã‚°ã§ã™:\"),\n",
    "    MessagesPlaceholder(variable_name=\"research_messages\"),\n",
    "    (\"human\", \"ä¸Šè¨˜ã‚’å…ƒã«ã€å¸‚å ´åˆ†æã®ãŸã‚ã®åŸºç¤ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\")\n",
    "])\n",
    "summary_chain = summary_prompt | model\n",
    "\n",
    "def summary_agent(state: State) -> dict:\n",
    "    print(\"ğŸ“ ã‚µãƒãƒªãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: èª¿æŸ»çµæœã‚’åˆ†æãƒãƒ¼ãƒ ã¸å…±æœ‰ã—ã¾ã™...\")\n",
    "    response = summary_chain.invoke({\"research_messages\": state[\"research_messages\"]})\n",
    "    return {\"analysis_messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ba8949",
   "metadata": {},
   "source": [
    "### å¸‚å ´åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc02e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¸‚å ´åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n",
    "market_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ã‚ãªãŸã¯å¸‚å ´åˆ†æã®ãƒ—ãƒ­ã§ã™ã€‚ãƒ¬ãƒãƒ¼ãƒˆã‚’å…ƒã«SWOTåˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚\"),\n",
    "    MessagesPlaceholder(variable_name=\"analysis_messages\")\n",
    "])\n",
    "market_chain = market_prompt | model\n",
    "\n",
    "def market_agent(state: State) -> dict:\n",
    "    print(\"ğŸ“ˆ å¸‚å ´åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: åˆ†æä¸­...\")\n",
    "    response = market_chain.invoke({\"analysis_messages\": state[\"analysis_messages\"]})\n",
    "    return {\"analysis_messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe354470",
   "metadata": {},
   "source": [
    "### æŠ€è¡“åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c42afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "technical_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ã‚ãªãŸã¯æŠ€è¡“ã®CTOã§ã™ã€‚å¸‚å ´åˆ†æã‚’è¸ã¾ãˆã€æŠ€è¡“çš„èª²é¡Œã¨å®Ÿç¾æ€§ã‚’æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚\"),\n",
    "    MessagesPlaceholder(variable_name=\"analysis_messages\")\n",
    "])\n",
    "technical_chain = technical_prompt | model\n",
    "\n",
    "# æŠ€è¡“åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n",
    "def technical_agent(state: State) -> dict:\n",
    "    print(\"ğŸ’» æŠ€è¡“åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: åˆ†æä¸­...\")\n",
    "    response = technical_chain.invoke({\"analysis_messages\": state[\"analysis_messages\"]})\n",
    "    return {\"analysis_messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e51b4e",
   "metadata": {},
   "source": [
    "### Human-in-the-loop (HITL) ãƒãƒ¼ãƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d4f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HITLãƒãƒ¼ãƒ‰\n",
    "def human_approval_node(state: State) -> Command[Literal[\"market_agent\", \"report_agent\", \"__end__\"]]:\n",
    "    \"\"\"\n",
    "    - interrupt() ã®å¼•æ•°ï¼ˆpayloadï¼‰ã¯ JSON-serializable ãª dict ã‚’æ¨å¥¨\n",
    "    - resume ã•ã‚ŒãŸå€¤ãŒ interrupt() ã®æˆ»ã‚Šå€¤ã¨ã—ã¦å…¥ã£ã¦ãã‚‹\n",
    "    \"\"\"\n",
    "    # UI/ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã«æç¤ºã—ãŸã„æƒ…å ±ã‚’ payload ã«å…¥ã‚Œã‚‹ï¼ˆJSON-serializableï¼‰\n",
    "    payload = {\n",
    "        \"kind\": \"approval_request\",\n",
    "        \"question\": \"ã“ã“ã¾ã§ã®è­°è«–ã‚’æ‰¿èªã—ã¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™ã‹ï¼Ÿ\",\n",
    "        \"options\": [\"y\", \"n\", \"retry\"],\n",
    "        \"theme\": (\n",
    "            state[\"research_messages\"][0].content\n",
    "            if state.get(\"research_messages\") else \"\"\n",
    "        ),\n",
    "        \"analysis_preview\": [\n",
    "            {\n",
    "                \"type\": type(m).__name__,\n",
    "                \"content\": (m.content[:500] + \"â€¦\") if isinstance(m.content, str) and len(m.content) > 500 else m.content\n",
    "            }\n",
    "            for m in state.get(\"analysis_messages\", [])\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # interruptï¼šã“ã“ã§åœæ­¢ã—ã€resume å¾Œã¯ã€Œæˆ»ã‚Šå€¤ã€ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãŒå…¥ã‚‹\n",
    "    user_decision = interrupt(payload)\n",
    "\n",
    "    # å†é–‹å¾Œã®ãƒ­ã‚¸ãƒƒã‚¯\n",
    "    if isinstance(user_decision, str):\n",
    "        user_decision = user_decision.strip().lower()\n",
    "\n",
    "    if user_decision == \"y\":\n",
    "        print(\"âœ… æ‰¿èªã•ã‚Œã¾ã—ãŸã€‚æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚\")\n",
    "        return Command(goto=\"report_agent\")\n",
    "    elif user_decision == \"retry\":\n",
    "        print(\"ğŸ”„ è­°è«–ã‚’å†é–‹ã—ã¾ã™ï¼ˆå¸‚å ´åˆ†æã¸æˆ»ã‚‹ï¼‰\")\n",
    "        return Command(goto=\"market_agent\")\n",
    "    else:\n",
    "        print(\"ğŸ›‘ çµ‚äº†ã—ã¾ã™ï¼ˆãƒ¬ãƒãƒ¼ãƒˆã¯ä½œæˆã—ã¾ã›ã‚“ï¼‰ã€‚\")\n",
    "        return Command(goto=END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f2051",
   "metadata": {},
   "source": [
    "### ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed70c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    ã“ã‚Œã¾ã§ã®è­°è«–ã‚’ã™ã¹ã¦çµ±åˆã—ã€æŠ•è³‡å®¶å‘ã‘ã®å…·ä½“çš„ãªäº‹æ¥­ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n",
    "    æ–‡æœ«ã§ã®è³ªå•ã‚„ææ¡ˆã¯ç¦æ­¢ã§ã™ã€‚ã€Œä»¥ä¸Šã€ã§çµ‚ã‚ã‚‰ã›ã¦ãã ã•ã„ã€‚\n",
    "    \"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"analysis_messages\")\n",
    "])\n",
    "report_chain = report_prompt | model\n",
    "\n",
    "# ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n",
    "def report_agent(state: State) -> dict:\n",
    "    print(\"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: æœ€çµ‚æˆæœç‰©ã‚’ä½œæˆä¸­...\")\n",
    "    response = report_chain.invoke({\"analysis_messages\": state[\"analysis_messages\"]})\n",
    "    return {\"analysis_messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ecf94b",
   "metadata": {},
   "source": [
    "## 5. ã‚°ãƒ©ãƒ•æ§‹ç¯‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c1758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "\n",
    "# ãƒãƒ¼ãƒ‰è¿½åŠ \n",
    "builder.add_node(\"research_agent\", research_agent)\n",
    "builder.add_node(\"tools\", research_tool_node)\n",
    "builder.add_node(\"summary_agent\", summary_agent)\n",
    "builder.add_node(\"market_agent\", market_agent)\n",
    "builder.add_node(\"technical_agent\", technical_agent)\n",
    "builder.add_node(\"human_approval\", human_approval_node)\n",
    "builder.add_node(\"report_agent\", report_agent)\n",
    "\n",
    "# ã‚¨ãƒƒã‚¸å®šç¾© (Commandã‚’ä½¿ã£ã¦ã„ã‚‹ãŸã‚ã€æ˜ç¤ºçš„ãªadd_edgeã¯ãƒ•ãƒ­ãƒ¼ã®å›ºå®šéƒ¨åˆ†ã ã‘ã§OK)\n",
    "builder.add_edge(START, \"research_agent\")\n",
    "builder.add_edge(\"summary_agent\", \"market_agent\")\n",
    "builder.add_edge(\"market_agent\", \"technical_agent\")\n",
    "builder.add_edge(\"technical_agent\", \"human_approval\")\n",
    "builder.add_edge(\"report_agent\", END)\n",
    "\n",
    "# ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ï¼ˆinterrupt/resume ã‚’ä½¿ã†ãŸã‚ã« checkpointer ã¯å¿…é ˆï¼‰\n",
    "memory = InMemorySaver()\n",
    "app = builder.compile(checkpointer=memory)\n",
    "\n",
    "# ã‚°ãƒ©ãƒ•ã®å¯è¦–åŒ–\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d39e7c",
   "metadata": {},
   "source": [
    "## 6.ãƒ¡ã‚¤ãƒ³å‡¦ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55294425",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = str(uuid.uuid4())\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "# ãƒ†ãƒ¼ãƒå…¥åŠ›\n",
    "initial_theme = input(\"ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:\") or \"å®‡å®™ã‚´ãƒŸã®å›åäº‹æ¥­\"\n",
    "print(f\"ãƒ†ãƒ¼ãƒï¼š{initial_theme}\")\n",
    "\n",
    "# åˆæœŸã‚¹ãƒ†ãƒ¼ãƒˆ\n",
    "initial_state = {\n",
    "    \"research_messages\": [HumanMessage(content=f\"ãƒ†ãƒ¼ãƒ: {initial_theme}\")],\n",
    "    \"loop_count\": 0,\n",
    "    \"analysis_messages\": [],\n",
    "}\n",
    "\n",
    "print(\"ğŸš€ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™...\")\n",
    "\n",
    "# ã¾ãšã¯æœ€åˆã®å®Ÿè¡Œï¼ˆå®Œäº†ã™ã‚‹ã‹ã€interrupt ã§æ­¢ã¾ã‚‹ã¾ã§é€²ã‚€ï¼‰\n",
    "result = app.invoke(initial_state, config=config)\n",
    "\n",
    "while True:\n",
    "    interrupts = result.get(\"__interrupt__\", None)\n",
    "\n",
    "    # 1) interrupt åˆ¤å®šï¼ˆåœæ­¢ä¸­ï¼‰\n",
    "    if interrupts:\n",
    "        # list/tuple/å˜ä½“ã©ã‚Œã§ã‚‚å—ã‘ã‚‹\n",
    "        first = interrupts[0] if isinstance(interrupts, (list, tuple)) else interrupts\n",
    "        # Interruptã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãªã‚‰ .valueã€ãã†ã§ãªã‘ã‚Œã°ãã®ã¾ã¾\n",
    "        interrupt_payload = getattr(first, \"value\", first)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 20 + \" ğŸ“ ã“ã“ã¾ã§ã®è­°è«–ã®ã¾ã¨ã‚ \" + \"=\" * 20)\n",
    "\n",
    "        # payload å´ã« analysis_preview ã‚’å…¥ã‚Œã¦ã„ã‚‹ã®ã§ã€ãã‚Œã‚’å„ªå…ˆã—ã¦è¡¨ç¤º\n",
    "        if isinstance(interrupt_payload, dict) and \"analysis_preview\" in interrupt_payload:\n",
    "            previews = interrupt_payload[\"analysis_preview\"]\n",
    "            if previews:\n",
    "                for item in previews:\n",
    "                    print(f\"\\n--- ğŸ—£ï¸ {item.get('type', 'Message')} ---\\n{item.get('content', '')}\\n\")\n",
    "            else:\n",
    "                print(\"ï¼ˆåˆ†æãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰\")\n",
    "        else:\n",
    "            # äº’æ›ï¼špayloadã«å«ã¾ã‚Œãªã„å ´åˆã¯ state ã‹ã‚‰è¡¨ç¤º\n",
    "            current_analysis = result.get(\"analysis_messages\", [])\n",
    "            if current_analysis:\n",
    "                for msg in current_analysis:\n",
    "                    content = msg.content if hasattr(msg, \"content\") else str(msg)\n",
    "                    content = content if isinstance(content, str) else str(content)\n",
    "                    print(f\"\\n--- ğŸ—£ï¸ {type(msg).__name__} ---\\n{content[:500]}...\\n(ä»¥ä¸‹ç•¥)\\n\")\n",
    "            else:\n",
    "                print(\"ï¼ˆåˆ†æãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰\")\n",
    "\n",
    "        print(\"=\" * 66 + \"\\n\")\n",
    "\n",
    "        # 2) æ‰¿èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆpayloadã®è³ªå•æ–‡ã‚’ä½¿ã†ï¼‰\n",
    "        if isinstance(interrupt_payload, dict):\n",
    "            question = interrupt_payload.get(\"question\", \"æ‰¿èªã—ã¾ã™ã‹ï¼Ÿ (y/n/retry)\")\n",
    "            options = interrupt_payload.get(\"options\", [\"y\", \"n\", \"retry\"])\n",
    "        else:\n",
    "            question = \"æ‰¿èªã—ã¾ã™ã‹ï¼Ÿ (y/n/retry)\"\n",
    "            options = [\"y\", \"n\", \"retry\"]\n",
    "\n",
    "        print(f\"âœ‹ ã€æ‰¿èªå¾…ã¡ã€‘{question}\")\n",
    "        print(f\"ğŸ¤– System Message: å…¥åŠ›ã—ã¦ãã ã•ã„ {options}\")\n",
    "\n",
    "        user_input = input(\"User Input (y/n/retry) > \").strip().lower()\n",
    "        print(f\"ğŸ”„ Resuming with input: '{user_input}'...\")\n",
    "\n",
    "        # 3) å†é–‹ï¼ˆresume å€¤ãŒ interrupt() ã®æˆ»ã‚Šå€¤ã«å…¥ã‚‹ï¼‰\n",
    "        result = app.invoke(Command(resume=user_input), config=config)\n",
    "        continue\n",
    "\n",
    "    # 2) å®Œäº†ï¼ˆinterrupt ãªã—ï¼‰\n",
    "    print(\"\\nâœ¨ å…¨å·¥ç¨‹ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")\n",
    "    analysis_messages = result.get(\"analysis_messages\", [])\n",
    "    if analysis_messages:\n",
    "        last = analysis_messages[-1]\n",
    "        last_content = last.content if hasattr(last, \"content\") else str(last)\n",
    "        print(\"=\" * 60)\n",
    "        print(last_content)\n",
    "        print(\"=\" * 60)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
