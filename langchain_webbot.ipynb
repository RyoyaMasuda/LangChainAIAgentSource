{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "999d7f42",
   "metadata": {},
   "source": [
    "# LangChainの応用：create_agentで作成するWeb検索連動チャットボット\n",
    "\n",
    "## 1.準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールをインポート\n",
    "import uuid # UUID（ランダムなID）生成用\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver # メモリ保存用\n",
    "from langchain_core.messages import AIMessageChunk\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 環境変数の読み込み\n",
    "load_dotenv()\n",
    "\n",
    "# モデル名\n",
    "MODEL_NAME = \"gpt-5-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78a63a8",
   "metadata": {},
   "source": [
    "## 2.ツールの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# ツールの初期化\n",
    "tavily_search = TavilySearch(\n",
    "    max_results=2,                 # 取得する検索結果の数\n",
    "    search_depth=\"basic\",          # \"basic\" (高速) か \"advanced\" (高品質)\n",
    "    include_answer=False,          # Tavilyが生成した短い回答を含めない\n",
    "    include_raw_content=False,     # HTMLの生コンテンツを含めるか（トークン消費増に注意）\n",
    "    include_images=False,          # 画像URLを含めるか\n",
    "    # include_domains=[\"go.jp\"],   # 特定のドメインのみ検索する場合\n",
    "    # exclude_domains=[\"wikipedia.org\"] # 特定のドメインを除外する場合\n",
    ")\n",
    "\n",
    "# Tavilyの検索結果だけを、LLMが読みやすい形に整形する関数\n",
    "def format_tavily_results(tavily_response: dict) -> str:\n",
    "    results = tavily_response.get(\"results\", [])\n",
    "    if not results:\n",
    "        return \"（検索結果なし）\"\n",
    "\n",
    "    lines = []\n",
    "    for i, r in enumerate(results, 1):\n",
    "        title = r.get(\"title\", \"\")\n",
    "        content = r.get(\"content\", \"\")\n",
    "        url = r.get(\"url\", \"\")\n",
    "        lines.append(f\"[{i}] {title}\\n{content}\\nsource: {url}\")\n",
    "    return \"\\n\\n\".join(lines)\n",
    "\n",
    "# TavilySearchの生レスポンス(dict/JSON)を整形して返すラッパーTool\n",
    "@tool\n",
    "def tavily_search_formatted(query: str) -> str:\n",
    "    \"\"\"Web検索（Tavily）。上位結果を整形して返す。\"\"\"\n",
    "    tavily_response = tavily_search.invoke({\"query\": query})\n",
    "    return format_tavily_results(tavily_response)\n",
    "\n",
    "# create_agent の tools に渡す\n",
    "tools = [tavily_search_formatted]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6409217",
   "metadata": {},
   "source": [
    "## 3.エージェントの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4069d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. モデルの初期化\n",
    "model = ChatOpenAI(model=MODEL_NAME)\n",
    "\n",
    "# 3. 記憶領域の初期化\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "prompt_text = \"\"\"\n",
    "ツール呼び出しを行った後に回答する場合は以下を行ってください。\n",
    "・回答の末尾に参照したsource番号（例：[1][2]）を付ける\n",
    "・最後にsource番号とurlを箇条書きで列挙する\n",
    "\"\"\"\n",
    "\n",
    "# 4. エージェントの作成（ツールを登録）\n",
    "# create_agentが自動的にツール呼び出しの判断ロジックを構築します\n",
    "search_agent = create_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    checkpointer=checkpointer,\n",
    "    system_prompt=prompt_text,\n",
    ")\n",
    "\n",
    "# グラフの可視化\n",
    "display(Image(search_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ef1f1",
   "metadata": {},
   "source": [
    "## 4.メインループ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2bf63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムなUUIDを生成して thread_id に設定\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"メッセージを入力:\")\n",
    "    if user_input.strip() == \"\":\n",
    "        break\n",
    "    print(f\"質問：{user_input}\")\n",
    "\n",
    "    # 検索中フラグ\n",
    "    is_spinning = False\n",
    "\n",
    "    # エージェントを実行し、応答をストリーミング表示\n",
    "    for chunk, metadata in search_agent.stream(\n",
    "        {\"messages\": [{\"role\": \"human\", \"content\": user_input}]},\n",
    "        config=config,\n",
    "        stream_mode=\"messages\"\n",
    "    ):\n",
    "        # 1. AIメッセージ（LLMの出力）のみを対象とする\n",
    "        if isinstance(chunk, AIMessageChunk):\n",
    "            # 2. ツール呼び出しの定義（JSON生成）中は表示しない\n",
    "            if chunk.tool_call_chunks:\n",
    "                if chunk.tool_call_chunks[-1][\"name\"] != None:\n",
    "                    print(\".\", end=\"\", flush=True) # 考え中の表現\n",
    "                    is_spinning = True\n",
    "                continue\n",
    "\n",
    "            # 3. コンテンツ（最終回答のテキスト）が含まれている場合のみ表示\n",
    "            if chunk.content:\n",
    "                if is_spinning:\n",
    "                    print() # 初回のみ改行を入れる\n",
    "                    is_spinning = False\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "    print() # 改行\n",
    "            \n",
    "print(\"\\n---ご利用ありがとうございました！---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
