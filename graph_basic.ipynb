{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc6f6bc2",
   "metadata": {},
   "source": [
    "# LangGraph入門\n",
    "\n",
    "## 1.準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe1c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールをインポート\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 環境変数の読み込み\n",
    "load_dotenv()\n",
    "\n",
    "# モデル名\n",
    "MODEL_NAME = \"gpt-5-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5911e8a",
   "metadata": {},
   "source": [
    "## 2.単純なグラフ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56992427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Any\n",
    "\n",
    "# 1. Stateの定義\n",
    "class State(TypedDict):\n",
    "    value: int\n",
    "\n",
    "# 2. ノード関数の定義\n",
    "def node_add1(state: State) -> dict[str, Any]:\n",
    "    return {\"value\": state[\"value\"] + 1}\n",
    "\n",
    "def node_double(state: State) -> dict[str, Any]:\n",
    "    return {\"value\": state[\"value\"] * 2}\n",
    "\n",
    "# 3. グラフの構築\n",
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_node(\"add\", node_add1)\n",
    "graph.add_node(\"double\", node_double)\n",
    "\n",
    "# STARTノードからaddへ接続\n",
    "graph.add_edge(START, \"add\")\n",
    "graph.add_edge(\"add\", \"double\")\n",
    "graph.add_edge(\"double\", END)\n",
    "\n",
    "# コンパイル\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c7e2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフの可視化\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e04c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期値として value に 10 を渡す\n",
    "initial_input = {\"value\": 10}\n",
    "\n",
    "# グラフを実行 (invoke)\n",
    "result = app.invoke(initial_input)\n",
    "\n",
    "print(f\"実行結果: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c2f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 実行プロセスの追跡 ---\")\n",
    "inputs = {\"value\": 10}\n",
    "\n",
    "# 各ステップごとに何が起きたかを出力\n",
    "for step in app.stream(inputs):\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd615ce",
   "metadata": {},
   "source": [
    "## 3.状態の保持、条件分岐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Literal\n",
    "from langgraph.types import Command\n",
    "\n",
    "# Stateの定義\n",
    "class State(TypedDict):\n",
    "    count: int\n",
    "    value: int\n",
    "\n",
    "# カウンタを1アップし、条件によって遷移先を変えるノード\n",
    "def node_count(state: State) -> Command[Literal[\"node_double\", END]]:\n",
    "    new_count = state[\"count\"] + 1\n",
    "\n",
    "    # 状態更新と同時に、次の遷移先を指定（Command）\n",
    "    if new_count < 3:\n",
    "        print(f\"Count: {new_count} -> Next: double\")\n",
    "        return Command(\n",
    "            update={\"count\": new_count},\n",
    "            goto=\"node_double\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Count: {new_count} -> Finish\")\n",
    "        return Command(\n",
    "            update={\"count\": new_count},\n",
    "            goto=END\n",
    "        )\n",
    "\n",
    "def node_double(state: State) -> Command[Literal[\"node_count\"]]:\n",
    "    # 単純な遷移もCommandで記述可能（gotoのみ指定も可）\n",
    "    return Command(\n",
    "        update={\"value\": state[\"value\"] * 2},\n",
    "        goto=\"node_count\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712bd7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフの構築\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"node_count\", node_count)\n",
    "graph.add_node(\"node_double\", node_double)\n",
    "\n",
    "# エッジ定義は「開始地点からnode_count」だけでOK\n",
    "graph.add_edge(START, \"node_count\") \n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f96b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフの可視化\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90050a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- 実行プロセスの追跡 ---\")\n",
    "inputs = {\"count\": 0, \"value\": 1}\n",
    "\n",
    "# 各ステップごとに何が起きたかを出力\n",
    "for step in app.stream(inputs):\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb4a0a",
   "metadata": {},
   "source": [
    "## 4.LLMの呼出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eee0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Any\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# 1. ステートの定義\n",
    "class State(TypedDict):\n",
    "    # add_messages はメッセージの追加・更新（IDベース）を自動処理するReducer\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    animal: str\n",
    "    voice: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6679ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. プロンプトとモデルの準備\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"あなたは{animal}らしく、語尾に{voice}などと付けて答えます。\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(model=MODEL_NAME)\n",
    "\n",
    "# チェーンの作成\n",
    "my_chain = prompt | model\n",
    "\n",
    "# 3. ノードの定義\n",
    "def chatbot(state: State) -> dict[str, Any]:\n",
    "    # チェーンの実行\n",
    "    response = my_chain.invoke({\n",
    "        \"animal\": state[\"animal\"],\n",
    "        \"voice\": state[\"voice\"],\n",
    "        \"messages\": state[\"messages\"],\n",
    "    })\n",
    "\n",
    "    # 更新差分を返す（add_messagesにより、既存リストに追加される）\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c13e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. グラフの構築\n",
    "graph = StateGraph(State)\n",
    "\n",
    "# ノードの追加\n",
    "graph.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# エッジの定義\n",
    "graph.add_edge(START, \"chatbot\")\n",
    "graph.add_edge(\"chatbot\", END)\n",
    "\n",
    "# グラフのコンパイル\n",
    "app = graph.compile()\n",
    "\n",
    "# 5. グラフの可視化\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f26159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. グラフの実行\n",
    "input_data = {\n",
    "    \"animal\": \"犬\",\n",
    "    \"voice\": \"ワン！\",\n",
    "    \"messages\": [HumanMessage(content=\"英語学習をする上でのポイントは？\")]\n",
    "}\n",
    "\n",
    "# 最終結果の表示\n",
    "response = app.invoke(input_data)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d7e2a",
   "metadata": {},
   "source": [
    "# 5.任意の関数をノードとして定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa620fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Any\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 1. ステートの定義\n",
    "class State(TypedDict):\n",
    "    question: str       # ユーザーからの質問\n",
    "    raw_response: str   # LLMが生成した生のテキスト\n",
    "    final_answer: str   # 加工後の最終回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの準備\n",
    "model = ChatOpenAI(model=MODEL_NAME)\n",
    "\n",
    "# 2. ノードの定義\n",
    "# プロンプトの準備\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{question}\\n\\n上記の質問について簡潔に回答してください。\"),\n",
    "])\n",
    "\n",
    "# チェーンの作成と実行\n",
    "my_chain = prompt | model | StrOutputParser()    \n",
    "\n",
    "# ノードA: LLMによる回答生成のみを担当\n",
    "def generation_node(state: State) -> dict[str, Any]:\n",
    "    response = my_chain.invoke({\"question\": state[\"question\"]})\n",
    "    \n",
    "    # 状態の「差分」を返す。これにより state[\"raw_response\"] が更新される\n",
    "    return {\"raw_response\": response}\n",
    "\n",
    "# ノードB: 任意の関数（文字列操作）を担当\n",
    "def reverse_string_node(state: State) -> dict[str, Any]:\n",
    "    # 前のノードの結果をステートから取得\n",
    "    original_text = state[\"raw_response\"]\n",
    "    \n",
    "    # 任意の関数処理（ここでは文字列反転）\n",
    "    reversed_text = original_text[::-1]\n",
    "    \n",
    "    # 処理結果を最終回答としてステートに書き込む\n",
    "    return {\"final_answer\": reversed_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. グラフの構築\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# ノードを追加\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reverse_process\", reverse_string_node)\n",
    "\n",
    "# エッジ（流れ）の定義\n",
    "# START -> 生成 -> 加工 -> END\n",
    "builder.add_edge(START, \"generate\")\n",
    "builder.add_edge(\"generate\", \"reverse_process\")\n",
    "builder.add_edge(\"reverse_process\", END)\n",
    "\n",
    "# コンパイル\n",
    "app = builder.compile()\n",
    "\n",
    "# グラフの可視化\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99be01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフの実行\n",
    "inputs = {\"question\": \"あなたの趣味は何ですか？\"}\n",
    "result = app.invoke(inputs)\n",
    "\n",
    "print(f\"質問: {result['question']}\")\n",
    "print(f\"LLMの回答 (raw): {result['raw_response']}\")\n",
    "print(f\"関数処理後 (final): {result['final_answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c7b6e1",
   "metadata": {},
   "source": [
    "## 6.複数のノードを並列につなげる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Any\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 1. ステートの定義\n",
    "# TypedDictを使用して型を定義します。\n",
    "# 並列実行でも、キーが異なれば競合せずにマージされます。\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    positive: str\n",
    "    negative: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e463a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. プロンプトとチェーンの準備\n",
    "positive_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"あなたは楽観主義者です。ユーザーからの質問に対して常に前向きな回答をします。\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "negative_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"あなたは悲観主義者です。ユーザーからの質問に対して常に否定的な回答をします。\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "opinion_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"あなたは平等主義者です。2つの意見を平等にまとめます。まとめた結果だけを出力します。\"),\n",
    "    (\"human\", \"楽観的な意見: {positive}\\n悲観的な意見: {negative}\"),\n",
    "])\n",
    "\n",
    "# モデルのセットアップ\n",
    "model = ChatOpenAI(model=MODEL_NAME)\n",
    "\n",
    "# 3. ノードの定義\n",
    "positive_chain = positive_prompt | model | StrOutputParser()\n",
    "def positive_node(state: State) -> dict[str, Any]:\n",
    "    return {\"positive\": positive_chain.invoke({\"question\": state[\"question\"]})}\n",
    "\n",
    "negative_chain = negative_prompt | model | StrOutputParser()\n",
    "def negative_node(state: State) -> dict[str, Any]:\n",
    "    return {\"negative\": negative_chain.invoke({\"question\": state[\"question\"]})}\n",
    "\n",
    "opinion_chain = opinion_prompt | model | StrOutputParser()\n",
    "def opinion_node(state: State) -> dict[str, Any]:\n",
    "    # ここに来る時点で、positiveとnegativeの両方がstateに入っています\n",
    "    return {\"answer\": opinion_chain.invoke(state)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbe55f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. グラフの構築\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# ノードの追加\n",
    "builder.add_node(\"positive_agent\", positive_node)\n",
    "builder.add_node(\"negative_agent\", negative_node)\n",
    "builder.add_node(\"opinion_agent\", opinion_node)\n",
    "\n",
    "# 並列実行の定義 (Fork)\n",
    "# STARTから複数のノードにエッジを張ることで、これらが同時に起動します\n",
    "builder.add_edge(START, \"positive_agent\")\n",
    "builder.add_edge(START, \"negative_agent\")\n",
    "\n",
    "# 合流の定義 (Join)\n",
    "# 両方のエッジを同じノードに向けることで、両方の処理が終わった後に次が実行されます\n",
    "# LangGraphのスーパー・ステップ機能により、自動的に待機・マージが行われます\n",
    "builder.add_edge(\"positive_agent\", \"opinion_agent\")\n",
    "builder.add_edge(\"negative_agent\", \"opinion_agent\")\n",
    "\n",
    "# 終了定義\n",
    "builder.add_edge(\"opinion_agent\", END)\n",
    "\n",
    "# コンパイル\n",
    "app = builder.compile()\n",
    "\n",
    "# 5. グラフの可視化と実行\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387c5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. グラフの実行\n",
    "print(\"--- 実行開始 ---\")\n",
    "initial_state = {\"question\": \"AIの進化が人間に与える影響は？\"}\n",
    "\n",
    "# streamで実行経過を確認\n",
    "for output in app.stream(initial_state):\n",
    "    for key, value in output.items():\n",
    "        print(f\"\\nCompleted Node: {key}\")\n",
    "        # 出力が見やすいように整形\n",
    "        if \"positive\" in value:\n",
    "            print(f\"Positive: {value['positive'][:50]}...\")\n",
    "        elif \"negative\" in value:\n",
    "            print(f\"Negative: {value['negative'][:50]}...\")\n",
    "        elif \"answer\" in value:\n",
    "            print(f\"\\nFinal Answer:\\n{value['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16222eab",
   "metadata": {},
   "source": [
    "## 7.チャットボットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a060ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Any\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 1. ステートの定義\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "# 2. プロンプトとモデルの準備\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"あなたは親切なアシスタントです。\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(model=MODEL_NAME)\n",
    "\n",
    "# チェーンの構築\n",
    "my_chain = prompt | model\n",
    "\n",
    "# 3. ノードの定義\n",
    "def chatbot_node(state: State) -> dict[str, Any]:\n",
    "    response = my_chain.invoke(state)\n",
    "    \n",
    "    # 更新差分（AIのメッセージ）を返します\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3981846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid # UUID（ランダムなID）生成用\n",
    "from langgraph.checkpoint.memory import InMemorySaver # メモリ保存用\n",
    "\n",
    "# 4. グラフの構築\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"chatbot\", chatbot_node)\n",
    "\n",
    "# エッジの定義 (START -> chatbot -> END)\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Checkpointerの初期化\n",
    "memory = InMemorySaver()\n",
    "\n",
    "# コンパイル時にcheckpointerを渡す\n",
    "# これにより、グラフはスレッドIDに基づいて状態を保存・復元できるようになる\n",
    "agent = builder.compile(checkpointer=memory)\n",
    "\n",
    "# グラフの可視化\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b244a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムなUUIDを生成して thread_id に設定\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "while True:\n",
    "    # ユーザーからの質問を受付\n",
    "    user_input = input(\"メッセージを入力:\")\n",
    "    # 質問が入力されなければ終了\n",
    "    if user_input.strip() == \"\":\n",
    "        break\n",
    "    print(f\"質問：{user_input}\")\n",
    "    \n",
    "    # エージェントを実行し、応答をストリーミング表示\n",
    "    # configを渡すことで、メモリから過去の会話をロードします\n",
    "    for chunk, metadata in agent.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config=config, \n",
    "        stream_mode=\"messages\"\n",
    "    ):\n",
    "        # chunkは AIMessageChunk オブジェクトなどが返ってきます\n",
    "        if hasattr(chunk, \"content\") and chunk.content:\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            \n",
    "    print() # 改行\n",
    "\n",
    "print(\"\\n---ご利用ありがとうございました！---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
