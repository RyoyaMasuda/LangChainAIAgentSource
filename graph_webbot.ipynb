{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb4eb15",
   "metadata": {},
   "source": [
    "# Web検索連動チャットボット（LangGraph版）の構築\n",
    "\n",
    "## 1.準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e172f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated, Any\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from langchain_tavily import TavilySearch\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "import uuid\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.messages import AIMessageChunk, BaseMessage\n",
    "\n",
    "# 環境変数の読み込み\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "# モデル名\n",
    "MODEL_NAME = \"gpt-5-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0298a87c",
   "metadata": {},
   "source": [
    "## 2. ツールの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b0f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ツールの初期化\n",
    "tavily_search = TavilySearch(\n",
    "    max_results=2,                 # 取得する検索結果の数\n",
    "    search_depth=\"basic\",          # \"basic\" (高速) か \"advanced\" (高品質)\n",
    "    include_answer=False,          # Tavilyが生成した短い回答を含めない\n",
    "    include_raw_content=False,     # HTMLの生コンテンツを含めるか（トークン消費増に注意）\n",
    "    include_images=False,          # 画像URLを含めるか\n",
    "    # include_domains=[\"go.jp\"],   # 特定のドメインのみ検索する場合\n",
    "    # exclude_domains=[\"wikipedia.org\"] # 特定のドメインを除外する場合\n",
    ")\n",
    "\n",
    "# Tavilyの検索結果だけを、LLMが読みやすい形に整形する関数\n",
    "def format_tavily_results(tavily_response: dict) -> str:\n",
    "    results = tavily_response.get(\"results\", [])\n",
    "    if not results:\n",
    "        return \"（検索結果なし）\"\n",
    "\n",
    "    lines = []\n",
    "    for i, r in enumerate(results, 1):\n",
    "        title = r.get(\"title\", \"\")\n",
    "        content = r.get(\"content\", \"\")\n",
    "        url = r.get(\"url\", \"\")\n",
    "        lines.append(f\"[{i}] {title}\\n{content}\\nsource: {url}\")\n",
    "    return \"\\n\\n\".join(lines)\n",
    "\n",
    "# TavilySearchの生レスポンス(dict/JSON)を整形して返すラッパーTool\n",
    "@tool\n",
    "def tavily_search_formatted(query: str) -> str:\n",
    "    \"\"\"Web検索（Tavily）。上位結果を整形して返す。\"\"\"\n",
    "    tavily_response = tavily_search.invoke({\"query\": query})\n",
    "    return format_tavily_results(tavily_response)\n",
    "\n",
    "@tool\n",
    "def internal_search(query: str) -> str:\n",
    "    \"\"\"（デモ用モック）Lucky社の社内規則を返す\"\"\"\n",
    "\n",
    "    rules = \"\"\"\n",
    "        Lucky社 社内規則\n",
    "        毎朝、鏡の中の自分に「今日はツイている」と宣言してから業務を始めること。\n",
    "        同僚の成功を自分のことのように喜び、社内の「運気」を循環させること。\n",
    "        どんなトラブルも、まずは「ラッキー！」と口に出してから解決策を考えること。\n",
    "        \"\"\"\n",
    "    return rules\n",
    "\n",
    "tools = [tavily_search_formatted, internal_search]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c025cf",
   "metadata": {},
   "source": [
    "## 3. ノードとグラフの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7eafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "# モデルの初期化\n",
    "model = ChatOpenAI(model=MODEL_NAME)\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "prompt_text = \"\"\"\n",
    "あなたは役に立つアシスタントです。必要に応じて最適なツールを使用してください。\n",
    "ツール呼び出しを行った後に回答する場合（ツール結果にURLが含まれる場合のみ）は以下を行ってください。\n",
    "・回答の末尾に参照したsource番号（例：[1][2]）を付ける\n",
    "・最後にsource番号とurlを箇条書きで列挙する\n",
    "\"\"\"\n",
    "\n",
    "# プロンプトテンプレートはシンプルに構築\n",
    "# SystemMessageを追加しておくと挙動が安定します\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt_text),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "my_chain = prompt | model_with_tools\n",
    "\n",
    "# チャットボットノード\n",
    "def chatbot(state: State) -> dict[str, Any]:\n",
    "    response = my_chain.invoke(state)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# ToolNodeの使用（並列ツール実行も自動対応）\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフの構築\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# ノードの追加\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "builder.add_node(\"tools\", tool_node) # 名前は慣習的に \"tools\" とすることが多い\n",
    "\n",
    "# エッジの定義\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 条件付きエッジ (Routerの自動化)\n",
    "# 「ツール呼び出しがあるなら tools へ、なければ終了」というロジックは\n",
    "# prebuiltの tools_condition がやってくれます。\n",
    "builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# ツール実行後は必ずチャットボット（LLM）に戻って結果を要約させる\n",
    "builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# Checkpointerの初期化\n",
    "memory = InMemorySaver()\n",
    "\n",
    "# コンパイル時にcheckpointerを渡す\n",
    "search_agent = builder.compile(checkpointer=memory)\n",
    "\n",
    "# グラフの可視化\n",
    "display(Image(search_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cacfce",
   "metadata": {},
   "source": [
    "## 4.メインループ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75402ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムなUUIDを生成して thread_id に設定\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"メッセージを入力:\")\n",
    "    if user_input.strip() == \"\":\n",
    "        break\n",
    "    print(f\"質問：{user_input}\")\n",
    "\n",
    "    # 検索中フラグ\n",
    "    is_spinning = False\n",
    "\n",
    "    # エージェントを実行し、応答をストリーミング表示\n",
    "    for chunk, metadata in search_agent.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        config=config,\n",
    "        stream_mode=\"messages\"\n",
    "    ):\n",
    "        # 1. AIメッセージ（LLMの出力）のみを対象とする\n",
    "        if isinstance(chunk, AIMessageChunk):\n",
    "            # 2. ツール呼び出しの定義（JSON生成）中は表示しない\n",
    "            if chunk.tool_call_chunks:\n",
    "                if chunk.tool_call_chunks[-1][\"name\"] is not None:\n",
    "                    print(f\"[DEBUG]ツール呼び出し:{chunk.tool_call_chunks[-1]['name']}\", flush=True)\n",
    "                    is_spinning = True\n",
    "                continue\n",
    "\n",
    "            # 3. コンテンツ（最終回答のテキスト）が含まれている場合のみ表示\n",
    "            if chunk.content:\n",
    "                if is_spinning:\n",
    "                    print() # 初回のみ改行を入れる\n",
    "                    is_spinning = False\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "    print() # 改行\n",
    "            \n",
    "print(\"\\n---ご利用ありがとうございました！---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
